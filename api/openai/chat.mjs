// OpenAI Chat Completions Mock API
// ì§ì ‘ êµ¬í˜„ - ì„œë²„ë¦¬ìŠ¤ ìµœì í™”
// Node.js Functionsì—ì„œ Request/Response API ì‚¬ìš©

// Content type ê°ì§€ í•¨ìˆ˜
function detectContentType(message) {
  const content = message.toLowerCase();
  if (content.includes('markdown') || content.includes('md')) return 'markdown';
  if (content.includes('html')) return 'html';
  if (content.includes('json')) return 'json';
  return 'text';
}

// Mock ì‘ë‹µ ìƒì„± í•¨ìˆ˜
function generateMockResponse(messages, contentType) {
  const lastMessage = messages[messages.length - 1]?.content || '';
  
  const responses = {
    text: `ì•ˆë…•í•˜ì„¸ìš”! "${lastMessage}"ì— ëŒ€í•œ ì‘ë‹µì…ë‹ˆë‹¤. ì´ê²ƒì€ Mock ì‘ë‹µì…ë‹ˆë‹¤.`,
    markdown: `# Mock ì‘ë‹µ\n\n**ì‚¬ìš©ì ë©”ì‹œì§€**: ${lastMessage}\n\n## ì‘ë‹µ ë‚´ìš©\n\nì´ê²ƒì€ **Markdown** í˜•ì‹ì˜ Mock ì‘ë‹µì…ë‹ˆë‹¤.\n\n- ëª©ë¡ í•­ëª© 1\n- ëª©ë¡ í•­ëª© 2\n- ëª©ë¡ í•­ëª© 3\n\n\`\`\`javascript\nconsole.log('Mock ì‘ë‹µì…ë‹ˆë‹¤!');\n\`\`\``,
    html: `<div style="padding: 20px; border: 1px solid #ddd; border-radius: 8px;"><h2 style="color: #333;">Mock HTML ì‘ë‹µ</h2><p><strong>ì‚¬ìš©ì ë©”ì‹œì§€:</strong> ${lastMessage}</p><p>ì´ê²ƒì€ <em>HTML í˜•ì‹</em>ì˜ Mock ì‘ë‹µì…ë‹ˆë‹¤.</p><ul><li>ìŠ¤íƒ€ì¼ì´ ì ìš©ëœ ëª©ë¡</li><li>ì¸ë¼ì¸ CSS í¬í•¨</li></ul></div>`,
    json: JSON.stringify({
      response: "Mock JSON ì‘ë‹µ",
      userMessage: lastMessage,
      data: {
        items: ["í•­ëª© 1", "í•­ëª© 2", "í•­ëª© 3"],
        timestamp: new Date().toISOString(),
        mockType: "json"
      }
    }, null, 2)
  };
  
  return responses[contentType] || responses.text;
}

// OpenAI API í˜•ì‹ì˜ ì‘ë‹µ ìƒì„±
function createOpenAIResponse(content, streaming = false) {
  const baseResponse = {
    id: `chatcmpl-${Math.random().toString(36).substr(2, 9)}`,
    object: streaming ? 'chat.completion.chunk' : 'chat.completion',
    created: Math.floor(Date.now() / 1000),
    model: 'gpt-3.5-turbo',
    choices: [{
      index: 0,
      finish_reason: streaming ? null : 'stop'
    }]
  };

  if (streaming) {
    baseResponse.choices[0].delta = { content };
  } else {
    baseResponse.choices[0].message = {
      role: 'assistant',
      content
    };
  }

  return baseResponse;
}

// POST /api/openai/chat (í”„ë¡ íŠ¸ì—ì„  /v1/chat/completionsë¡œ rewrite)
export default async function handler(request) {
  console.log('ğŸš€ Mock API Handler called');
  
  if (request.method !== 'POST') {
    return new Response('Method not allowed', { status: 405 });
  }

  try {
    const body = await request.json();
    const { stream, messages } = body;
    
    console.log(`ğŸ“ Processing ${messages?.length || 0} messages, streaming: ${stream}`);
    
    // Content type ê°ì§€
    const lastMessage = messages?.[messages.length - 1];
    const contentType = detectContentType(lastMessage?.content || '');
    console.log(`ğŸ­ Detected content type: ${contentType}`);
    
    // Mock ì‘ë‹µ ìƒì„±
    const mockContent = generateMockResponse(messages, contentType);
    
    if (stream) {
      // ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
      const streamContent = new ReadableStream({
        async start(controller) {
          try {
            // ì‘ë‹µì„ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ìŠ¤íŠ¸ë¦¬ë°
            const chunks = mockContent.match(/.{1,10}/g) || [mockContent];
            
            for (let i = 0; i < chunks.length; i++) {
              const chunk = chunks[i];
              const response = createOpenAIResponse(chunk, true);
              
              // ë§ˆì§€ë§‰ ì²­í¬ì—ëŠ” finish_reason ì¶”ê°€
              if (i === chunks.length - 1) {
                response.choices[0].finish_reason = 'stop';
              }
              
              const data = `data: ${JSON.stringify(response)}\n\n`;
              controller.enqueue(new TextEncoder().encode(data));
              
              // ì‹¤ì œ ìŠ¤íŠ¸ë¦¬ë° ëŠë‚Œì„ ìœ„í•œ ì§€ì—°
              await new Promise(resolve => setTimeout(resolve, 50));
            }
            
            controller.enqueue(new TextEncoder().encode('data: [DONE]\n\n'));
            controller.close();
          } catch (error) {
            controller.error(error);
          }
        }
      });

      return new Response(streamContent, {
        headers: {
          'Content-Type': 'text/event-stream',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive',
        },
      });
    } else {
      // ì¼ë°˜ ì‘ë‹µ
      const response = createOpenAIResponse(mockContent, false);
      return new Response(JSON.stringify(response), {
        headers: { 'Content-Type': 'application/json' }
      });
    }
  } catch (err) {
    console.error('âŒ Mock API Error:', err);
    return new Response(JSON.stringify({ error: err.message }), {
      status: 500,
      headers: { 'Content-Type': 'application/json' }
    });
  }
}